{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"private_outputs":true,"provenance":[{"file_id":"https://github.com/TeachingTextMining/TextClassification/blob/main/03-SA-Transformers-Training-FineTuning/03-TextClassification-with-Transformers-FineTuning-Reviews.ipynb","timestamp":1702729441126}]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.9"},"gpuClass":"standard"},"cells":[{"cell_type":"markdown","metadata":{"id":"9pOlP10M0DBB"},"source":["# BERT Fine-Tuning\n"]},{"cell_type":"markdown","metadata":{"id":"e3XEbmh7WL96"},"source":["<a name=\"sec:setup\"></a>\n","### Instalación de librerías e importación de dependencias.\n"]},{"cell_type":"code","metadata":{"id":"jmn-i8APWMjm"},"source":["%%capture\n","!pip install transformers==4.26.0 tensorflow==2.11 pandas==1.3.5 plotly==5.5.0 scikit-learn==1.0.0"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"J0pI1gnw0DBF"},"source":["%reset -f\n","\n","import os\n","\n","import pandas as pd\n","from collections import Counter\n","from sklearn import preprocessing\n","from sklearn.utils.class_weight import compute_class_weight\n","\n","# para evaluar los modelos\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay, roc_curve, auc\n","from sklearn.utils.multiclass import unique_labels\n","\n","#  para construir gráficas y realizar análisis exploratorio de los datos\n","import plotly.graph_objects as go\n","import plotly.figure_factory as ff\n","import plotly.express as px\n","from tqdm import tqdm\n","\n","# para guardar el modelo\n","import pickle\n","import tensorflow as tf\n","\n","# algoritmos de clasificación, tokenizadores, etc.\n","from transformers import DistilBertTokenizer, TFDistilBertForSequenceClassification, DistilBertConfig, TextClassificationPipeline"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L3G3KQUyXSUg"},"source":["def get_model_inputs(cfg, data):\n","    encodings = cfg['tokenizer'](data, truncation=True, padding='max_length', max_length=cfg['max_length'], return_tensors=cfg['framework'])\n","\n","    inputs = {'input_ids': encodings['input_ids'],\n","            'attention_mask': encodings['attention_mask']\n","            }\n","    return inputs\n","\n","def predict_model(model, cfg, data, pref='m'):\n","  res = {}\n","  inputs = get_model_inputs(cfg, data)\n","  scores = model.predict(inputs)['logits']  # la salida de este modelo es TFSequenceClassifierOutput, debe tomarse el valor asociado a la llave 'logits'\n","\n","  if cfg['num_labels']==1: # si es clasificación binaria, este modelo devuelve solo 1 score por instancia\n","    res = {f'scores_{pref}': scores[:,0]}\n","  else:\n","    res = {f'scores_{pref}_{cls.lower()}': score for cls, score in zip(cfg['label_binarizer'].classes_, [col for col in scores.T])}\n","\n","  labels = cfg['label_binarizer'].inverse_transform(scores)\n","  res[f'labels_{pref}'] = labels\n","\n","  res = pd.DataFrame(res, columns=sorted(list(res.keys())))\n","  return res\n","\n","\n","def evaluate_model(y_true, y_pred, y_score=None, pos_label='positive'):\n","  print('==== Sumario de la clasificación ==== ')\n","  print(classification_report(y_true, y_pred))\n","\n","  print('Accuracy -> {:.2%}\\n'.format(accuracy_score(y_true, y_pred)))\n","\n","  # graficar matriz de confusión\n","  display_labels = sorted(unique_labels(y_true, y_pred), reverse=True)\n","  cm = confusion_matrix(y_true, y_pred, labels=display_labels)\n","\n","  z = cm[::-1]\n","  x = display_labels\n","  y =  x[::-1].copy()\n","  z_text = [[str(y) for y in x] for x in z]\n","\n","  fig_cm = ff.create_annotated_heatmap(z, x=x, y=y, annotation_text=z_text, colorscale='Viridis')\n","\n","  fig_cm.update_layout(\n","      height=400, width=400,\n","      showlegend=True,\n","      margin={'t':150, 'l':0},\n","      title={'text' : 'Matriz de Confusión', 'x':0.5, 'y':0.95, 'xanchor': 'center'},\n","      xaxis = {'title_text':'Valor Real', 'tickangle':45, 'side':'top'},\n","      yaxis = {'title_text':'Valor Predicho', 'tickmode':'linear'},\n","  )\n","  fig_cm.show()\n","\n","\n","  fig_roc = None\n","  if y_score is not None:\n","    fpr, tpr, thresholds = roc_curve(y_true, y_score, pos_label=pos_label)\n","    fig_roc = px.area(\n","        x=fpr, y=tpr,\n","        title = f'Curva ROC (AUC={auc(fpr, tpr):.4f})',\n","        labels=dict(x='Ratio Falsos Positivos', y='Ratio Verdaderos Positivos'),\n","        width=400, height=400\n","    )\n","    fig_roc.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)\n","\n","    fig_roc.update_yaxes(scaleanchor=\"x\", scaleratio=1)\n","    fig_roc.update_xaxes(constrain='domain')\n","\n","    fig_roc.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"60mgkkJJJTGi"},"source":["### Carga de datos\n","\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive', force_remount = True)"],"metadata":{"id":"ILhSGZbqY22T"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["text_col = 'combined'\n","class_col = 'label'\n","\n","train = pd.read_csv('/content/drive/MyDrive/TFM/v2/train_limpio_0_4.csv', index_col = 0)\n","train['combined'] = train.apply(lambda row: f\"{row['author'].lower()} [SEP] {row['candidate'].lower()}\", axis=1)\n","print(train.head())\n","val = pd.read_csv('/content/drive/MyDrive/TFM/v2/test_limpio_0_4.csv', index_col = 0)\n","val['combined'] = val.apply(lambda row: f\"{row['author'].lower()} [SEP] {row['candidate'].lower()}\", axis=1)\n","print(val.head())"],"metadata":{"id":"pKKnKUMMY-FY"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"fuKfnywyV86e"},"source":["### Modelo\n"]},{"cell_type":"code","metadata":{"id":"11NFa2reJ9fc"},"source":["# configuraciones\n","cfg = {}\n","cfg['framework'] = 'tf'\n","cfg['max_length'] = 512\n","cfg['transformer_model_name'] = 'bert-base-uncased'\n","cfg['num_labels'] = 1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"83jAjf5lKVL3"},"source":["#### Configuración del modelo"]},{"cell_type":"code","metadata":{"id":"veyHWjwn0DBM"},"source":["config = DistilBertConfig(num_labels=cfg['num_labels'], seq_classif_dropout=0.5)\n","\n","model = TFDistilBertForSequenceClassification.from_pretrained(cfg['transformer_model_name'], config=config)\n","\n","optimizer = tf.keras.optimizers.Adam(learning_rate=5e-5)\n","loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n","\n","model.compile(optimizer=optimizer, loss=loss, metrics=['binary_accuracy'])\n","\n","model.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zIXGmNO4YujW"},"source":["### Pre-procesamiento de los datos"]},{"cell_type":"markdown","metadata":{"id":"Zr5cOi6aKztL"},"source":["#### Instanciar tokenizador, etc."]},{"cell_type":"code","metadata":{"id":"_9sWr5OxK0ET"},"source":["cfg['tokenizer'] = DistilBertTokenizer.from_pretrained(cfg['transformer_model_name'] )\n","cfg['label_binarizer'] = preprocessing.LabelBinarizer()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BZDtSJp3N5ys"},"source":["#### Pre-procesamiento"]},{"cell_type":"code","metadata":{"id":"pNN4mqo6YusN"},"source":["cfg['label_binarizer'].fit(train[class_col])\n","\n","with open('label_binarizer_reviews.pkl', 'wb') as f:\n","    pickle.dump(cfg['label_binarizer'], f)\n","\n","train_blabels = cfg['label_binarizer'].transform(train[class_col])\n","val_blabes = cfg['label_binarizer'].transform(val[class_col])\n","\n","train_blabels_t = tf.convert_to_tensor(train_blabels, dtype='int32')\n","val_blabels_t = tf.convert_to_tensor(val_blabes, dtype='int32')\n","\n","train_inputs = get_model_inputs(cfg, train[text_col].to_list())\n","val_inputs = get_model_inputs(cfg, val[text_col].to_list())"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"x9L3WbPKZ5JA"},"source":["### Entrenamiento del modelo\n","Vamos a probar con el valor de epochs, entre 1 y 10."]},{"cell_type":"code","metadata":{"id":"6_zb7ESg0DBW"},"source":["# configuraciones\n","cfg['checkpoints_dir'] = 'checkpoints'\n","cfg['model_name'] = 'bert-authors'\n","cfg['trained_model_name'] = os.path.join(cfg['checkpoints_dir'], cfg['model_name'])\n","\n","epochs_max = 10\n","epochs_to_save = 1\n","batch_size = 16\n","histories = pd.DataFrame(None, columns = [\"epoch\", \"loss\", \"binary_accuracy\",\n","                                          \"val_loss\", \"val_binary_accuracy\"])\n","\n","for epoch_current in range(0, epochs_max, epochs_to_save):\n","    epoch_from = epoch_current +1\n","    epoch_to = epoch_current + epochs_to_save\n","    print(f'Training model, epochs {epoch_from} - {epoch_to}')\n","\n","    history = model.fit(train_inputs, y=train_blabels_t, initial_epoch=epoch_current, epochs=epoch_to,\n","                        batch_size=batch_size, validation_data=(val_inputs,val_blabels_t))\n","    histories = pd.concat([pd.DataFrame([[epoch_to, history.history['loss'][0],\n","                                          history.history['binary_accuracy'][0],\n","                                          history.history['val_loss'][0],\n","                                          history.history['val_binary_accuracy'][0]]],\n","                                          columns = histories.columns), histories], ignore_index = True)\n","\n","    model.save_pretrained(cfg['trained_model_name'] + f'-epochs-{epoch_from:03d}-{epoch_to:03d}', )\n","    cfg['tokenizer'].save_pretrained(cfg['trained_model_name'] + f'-epochs-{epoch_from:03d}-{epoch_to:03d}')\n","\n","    model_pkl_file = \"/content/drive/MyDrive/TFM/models/bert_v2_\" +  str(epoch_to) + \".pkl\"\n","    with open(model_pkl_file, 'wb') as file:\n","        pickle.dump(model, file)"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","\n","fig, (ax1, ax2) = plt.subplots(1, 2, figsize = (15, 5))\n","fig.suptitle('Train VS Validation')\n","\n","histories.plot.line(ax = ax1, x = 'epoch', y = ['binary_accuracy', 'val_binary_accuracy'], color = ['rebeccapurple', 'teal'])\n","ax1.set_title('Accuracy')\n","histories.plot.line(ax = ax2, x = 'epoch', y = ['loss', 'val_loss'], color = ['rebeccapurple', 'teal'])\n","ax2.set_title('Loss')\n","\n","plt.show()"],"metadata":{"id":"Ah7ltRbqj9j-"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["El mejor resultado es para 6 epochs."],"metadata":{"id":"I4LyMYZFlasc"}},{"cell_type":"code","source":["# configuraciones\n","cfg['checkpoints_dir'] = 'checkpoints'  # directorio donde se guardarán los checkpoints al entrenar el modelo\n","cfg['model_name'] = 'bert-authors'  # identificador al guardar los checkpoints\n","cfg['trained_model_name'] = os.path.join(cfg['checkpoints_dir'], cfg['model_name'])\n","\n","epochs_max = 10\n","epochs_to_save = 1\n","batch_size = 16\n","\n","for epoch_current in range(0, epochs_max, epochs_to_save):\n","    epoch_from = epoch_current +1\n","    epoch_to = epoch_current + epochs_to_save\n","    print(f'Training model, epochs {epoch_from} - {epoch_to}')\n","\n","    model.fit(train_inputs, y=train_blabels_t, initial_epoch=epoch_current, epochs=epoch_to, batch_size=batch_size, validation_data=(val_inputs,val_blabels_t))\n","\n","    model.save_pretrained(cfg['trained_model_name'] + f'-epochs-{epoch_from:03d}-{epoch_to:03d}', )\n","    cfg['tokenizer'].save_pretrained(cfg['trained_model_name'] + f'-epochs-{epoch_from:03d}-{epoch_to:03d}')"],"metadata":{"id":"9Cm5fl0Vlbqz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_gtuFJqtgUPi"},"source":["### Métricas"]},{"cell_type":"code","source":["model_pkl_file = \"/content/drive/MyDrive/TFM/models/bert_v2_6.pkl\"\n","with open(model_pkl_file, 'rb') as file:\n","    model = pickle.load(file)"],"metadata":{"id":"UyBpAnJmZjsp"},"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gcglNudkw2Rb"},"source":["data = val\n","true_labels = data[class_col]\n","\n","m_pred = predict_model(model, cfg, data[text_col].to_list(), pref='m')\n","\n","evaluate_model(true_labels, m_pred['labels_m'])  # notar que en este caso se no suministran los scores\n","\n","print('Done!')"],"execution_count":null,"outputs":[]}]}